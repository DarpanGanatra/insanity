# insanity
There's a lot going on in the AI space. This is my small corner of peace.

Table of Contents

- [Machine Learning](#machine-learning)
    - [Notebooks](#notebooks)
        - [Methods](#methods)
        - [Models](#models)
        - [Applications](#applications)
    - [References](#references)
- [Deep Learning](#deep-learning)
    - [Notebooks](#notebooks-1)
    - [References](#references-1)

## Machine Learning

### Notebooks
#### Methods
These will be shown in the context of a model. For example, feature engineering will be shown in the context of a linear regression model. This is to show how the methods are used in the real world. I will most likely use libraries like Optuna and Shap to add some depth to the methods, since 99% of the time, you will be using libraries to do the heavy lifting.
- :hourglass: [Hyperparameter Tuning](ML/Hyperparameter_Tuning.ipynb)
- :x: [Feature Engineering](ML/Feature_Engineering.ipynb)
- :x: [Feature Selection](ML/Feature_Selection.ipynb)
- :x: [Cross Validation](ML/Cross_Validation.ipynb)
- :x: [Evaluation Metrics](ML/Evaluation_Metrics.ipynb)
- :x: [Regularization](ML/Regularization.ipynb)
- :x: [Ensemble Learning](ML/Ensemble_Learning.ipynb)

TODO: Determine if these should be created.
- :x: [Bias and Variance](ML/Bias_and_Variance.ipynb)
- :x: [Imbalanced Classes](ML/Imbalanced_Classes.ipynb)

#### Models
Most of these will be very simple implementations of the models. I'm not trying to reinvent the wheel here. I just want to show how to use them in Python.

If you have any questions or suggestions, please open an issue and I'm happy to answer or add it to the list.

- :white_check_mark: [Linear Regression](ML/Linear_Regression.ipynb)
- :x: [Logistic Regression](ML/Logistic_Regression.ipynb)
- :x: [K-Nearest Neighbors](ML/K_Nearest_Neighbors.ipynb)
- :x: [Decision Trees](ML/Decision_Trees.ipynb)
- :x: [Random Forests](ML/Random_Forests.ipynb)
- :x: [Gradient Boosting](ML/Gradient_Boosting.ipynb)
- :x: [Support Vector Machines](ML/Support_Vector_Machines.ipynb)
- :x: [K-Means Clustering](ML/K_Means_Clustering.ipynb)
- :x: [Principal Component Analysis](ML/Principal_Component_Analysis.ipynb)

### Applications
TODO: Tag these with the methods and models used.
- :x: [Predicting Housing Prices](ML/Predicting_Housing_Prices.ipynb)
- :x: [Predicting Titanic Survivors](ML/Predicting_Titanic_Survivors.ipynb)
- :x: [Predicting Breast Cancer](ML/Predicting_Breast_Cancer.ipynb)


### References
TODO: FILL OUT

## Deep Learning
Yes, I understand deep learning is a subset of machine learning. I'm just trying to keep things organized.

Starting with how to use PyTorch for deep learning.

### Notebooks
- :x: [PyTorch Basics](DL/PyTorch_Basics.ipynb)

#### Neural Network Architectures
- :x: [Convolutional Neural Networks](DL/Convolutional_Neural_Networks.ipynb)
- :x: [Recurrent Neural Networks](DL/Recurrent_Neural_Networks.ipynb)
- :x: [Generative Adversarial Networks](DL/Generative_Adversarial_Networks.ipynb)
- :x: [Autoencoders](DL/Autoencoders.ipynb)

#### Applications
TODO: Show how to use the architectures above to solve problems in the real world.


### References
TODO: FILL OUT

## ML Ops

### Notebooks
- :x: [MLFlow](DL/MLFlow.ipynb)
- :x: [Kubeflow](DL/Kubeflow.ipynb)

### References
TODO: FILL OUT
